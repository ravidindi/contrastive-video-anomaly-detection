{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To create pickle file"
      ],
      "metadata": {
        "id": "bGjdKgb0enny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c81ojLYTlpM5",
        "outputId": "7179965f-ee7d-4d73-c650-c913c5edc23a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 21.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n"
          ]
        }
      ],
      "source": [
        "!pip install pickle5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source for resources"
      ],
      "metadata": {
        "id": "pTC_-CnLetpU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyg2QtOAluPX",
        "outputId": "6389d92f-83a0-45f9-b61a-fda0498956db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RGB Feature extraction code using I3D"
      ],
      "metadata": {
        "id": "DaX7hMkReyt0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjueLoAgl5Rd",
        "outputId": "26df02b2-7b47-4a85-c993-982870d27c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'video_features'...\n",
            "remote: Enumerating objects: 615, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 615 (delta 13), reused 53 (delta 11), pack-reused 555\u001b[K\n",
            "Receiving objects: 100% (615/615), 163.81 MiB | 24.20 MiB/s, done.\n",
            "Resolving deltas: 100% (279/279), done.\n",
            "Checking out files: 100% (71/71), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting omegaconf==2.0.6\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.0.6) (4.1.1)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 11.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyYAML, omegaconf\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.2.0+cu92 which is incompatible.\n",
            "fastai 2.6.3 requires torchvision>=0.8.2, but you have torchvision 0.4.0+cu92 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 omegaconf-2.0.6\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/v-iashin/video_features.git\n",
        "! pip install omegaconf==2.0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzZAb08xmAL9",
        "outputId": "ba17fcc1-a824-48d8-a2eb-46a6339b4bdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/video_features\n"
          ]
        }
      ],
      "source": [
        "%cd video_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eyk2cAw7mExl",
        "outputId": "3ad9c0fc-1823-4229-e378-b1ae59255513"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from models.i3d.extract_i3d import ExtractI3D\n",
        "from utils.utils import build_cfg_path, action_on_extraction\n",
        "from omegaconf import OmegaConf\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfs0S7EJmHX9",
        "outputId": "a8492807-9ecd-4352-94ca-d2746accb5b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [14:34<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "feature_type = 'i3d'\n",
        "folder_name='/content/drive/MyDrive/normal'\n",
        "args = OmegaConf.load(build_cfg_path(feature_type))\n",
        "args.video_paths = [''.join([folder_name, '/', i]) for i in os.listdir(folder_name)]\n",
        "args.extraction_fps = 32\n",
        "args.flow_type = 'raft' \n",
        "# Load the model\n",
        "extractor = ExtractI3D(args)\n",
        "model, class_head = extractor.load_model(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rFA6ZqlmQtX",
        "outputId": "2e291a1c-04a1-4fef-ea02-67a151e4ec0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting for /content/drive/MyDrive/videos/test/Abuse021_x264.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:878: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool3d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rgb\n",
            "(29, 1024)\n",
            "[[0.17639388 0.16362235 0.08643608 ... 0.20163435 0.09561009 0.36968425]\n",
            " [0.15564016 0.14053313 0.09952687 ... 0.28724939 0.11044361 0.07901865]\n",
            " [0.14319526 0.12440646 0.07436462 ... 0.20050241 0.0872099  0.18753216]\n",
            " ...\n",
            " [0.03464679 0.1785682  0.02845623 ... 0.25127223 0.27494383 0.01454003]\n",
            " [0.04891974 0.17799912 0.03707507 ... 0.23741707 0.28684804 0.00339542]\n",
            " [0.05168566 0.23673862 0.03044268 ... 0.32710525 0.41802523 0.00241226]]\n",
            "flow\n",
            "(29, 1024)\n",
            "[[2.58572884e-02 3.62819880e-02 3.20087783e-02 ... 4.11930569e-02\n",
            "  8.66518170e-03 1.07087968e-02]\n",
            " [5.33869527e-02 3.92315686e-02 4.88899387e-02 ... 1.60588726e-01\n",
            "  1.52154760e-02 1.76815733e-01]\n",
            " [4.57010977e-02 8.37122053e-02 2.82003041e-02 ... 2.38117371e-02\n",
            "  2.08317372e-03 3.05324644e-02]\n",
            " ...\n",
            " [3.10656615e-02 2.29972526e-02 2.52324864e-02 ... 2.40503866e-02\n",
            "  6.74996758e-03 1.67466242e-05]\n",
            " [3.49405594e-02 3.20860557e-02 2.99913976e-02 ... 3.62285227e-02\n",
            "  9.52131860e-03 7.70747196e-03]\n",
            " [5.65976948e-02 4.21895497e-02 5.84651455e-02 ... 2.47742802e-01\n",
            "  2.64120754e-02 7.73206819e-03]]\n",
            "fps\n",
            "()\n",
            "30.0\n",
            "timestamps_ms\n",
            "(29,)\n",
            "[ 2133.33333333  4266.66666667  6400.          8533.33333333\n",
            " 10666.66666667 12800.         14933.33333333 17066.66666667\n",
            " 19200.         21333.33333333 23466.66666667 25600.\n",
            " 27733.33333333 29866.66666667 32000.         34133.33333333\n",
            " 36266.66666667 38400.         40533.33333333 42666.66666667\n",
            " 44800.         46933.33333333 49066.66666667 51200.\n",
            " 53333.33333333 55466.66666667 57600.         59733.33333333\n",
            " 61866.66666667]\n"
          ]
        }
      ],
      "source": [
        "for video_path in args.video_paths:\n",
        "    print(f'Extracting for {video_path}')\n",
        "    features = extractor.extract(device, model, class_head, video_path)\n",
        "    [(print(k), print(v.shape), print(v)) for k, v in features.items()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO4qAbJZmYl3"
      },
      "outputs": [],
      "source": [
        "d={'feature':features['rgb'],'label':1,'num':features['rgb'].shape[0]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WL-4o6EodV-",
        "outputId": "f050c6e7-4415-4d75-b215-5b45efa07f7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'feature': array([[0.04317187, 0.32686621, 0.36206684, ..., 0.30663067, 0.20909926,\n",
              "         0.52908981],\n",
              "        [0.03676441, 0.38669893, 0.36596587, ..., 0.24567421, 0.21397777,\n",
              "         0.43830228],\n",
              "        [0.03689408, 0.39327082, 0.37186712, ..., 0.24284343, 0.28328985,\n",
              "         0.48415518],\n",
              "        ...,\n",
              "        [0.02944066, 0.35002196, 0.36165994, ..., 0.21700065, 0.26356268,\n",
              "         0.30547273],\n",
              "        [0.03131689, 0.34578332, 0.36757511, ..., 0.25258383, 0.30103743,\n",
              "         0.45221433],\n",
              "        [0.03205033, 0.36976871, 0.32989234, ..., 0.26204252, 0.26245707,\n",
              "         0.41826856]]), 'label': 1, 'num': 40}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu2SjvyJoeT0"
      },
      "outputs": [],
      "source": [
        "import pickle5 as pickle\n",
        "with open('datatest.pkl', 'wb') as handle:\n",
        "    pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for video_path in args.video_paths:\n",
        "    print(f'Extracting for {video_path}') \n",
        "    features = extractor.extract(device, model, class_head, video_path)\n",
        "    ls.append({'feature':features['rgb'], 'label':0,'num':features['rgb'].shape[0]})\n",
        "with open('/content/drive/MyDrive/data/train/data_1.pkl', 'wb') as handle:\n",
        "  pickle.dump(ls, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "SivNS818ejXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing python torch version"
      ],
      "metadata": {
        "id": "FuJLP0roe8S6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baBPPccmpqjd",
        "outputId": "ec926a09-bf32-4f42-b47c-12fda7aaa2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.2.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 663.1 MB 1.7 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 62.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0+cu92) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.2.0+cu92 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.2.0+cu92 which is incompatible.\n",
            "fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.2.0+cu92 which is incompatible.\n",
            "fastai 2.6.3 requires torchvision>=0.8.2, but you have torchvision 0.4.0+cu92 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "uU01lguQfEHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u6ZI3mP6qYEd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import pdb\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(Attention, self).__init__()\n",
        "        self.conv = nn.Conv2d(1024, 256, 1)\n",
        "        self.gcn = GCN(opt, 256, 256)\n",
        "        self.fc = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1024, 1, 1)\n",
        "        x = self.conv(x)\n",
        "        # x = torch.tanh(x)\n",
        "        x = F.relu(x,inplace=False)\n",
        "        x = x.clone().view(-1, 256)\n",
        "        A = self.gcn(x)\n",
        "        x = self.fc(x)\n",
        "        mask = torch.sigmoid(x) + 1e-5\n",
        "        inverse_mask = torch.reciprocal(mask)\n",
        "        return mask, inverse_mask\n",
        "\n",
        "\n",
        "class Classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classification, self).__init__()\n",
        "        self.fc = nn.Linear(1024, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.fc(x))\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        super(Network, self).__init__()\n",
        "        self.attention = Attention(opt)\n",
        "        self.classification = Classification()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        mask, inverse_mask = self.attention(x)\n",
        "        video_feature = torch.sum(x * mask, dim=0, keepdim=True) / torch.sum(mask)\n",
        "        video_score = self.classification(video_feature)\n",
        "        inverse_video_feature = torch.sum(x * inverse_mask, dim=0, keepdim=True) / torch.sum(inverse_mask)\n",
        "        inverse_video_score = self.classification(inverse_video_feature)\n",
        "        segments_scores = self.classification(x)\n",
        "        return video_score, inverse_video_score, mask, segments_scores\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, opt, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.opt = opt\n",
        "        if self.opt.C:\n",
        "            self.theta = nn.Linear(in_channels, in_channels)\n",
        "            self.phi = nn.Linear(in_channels, in_channels)\n",
        "        self.conv_d = nn.Linear(in_channels, out_channels)\n",
        "        if opt.residual:\n",
        "            self.down = nn.Sequential(nn.Conv1d(in_channels, out_channels, kernel_size=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        t, c = x.size()\n",
        "        A, M = self.generate_A(t, self.opt.width)\n",
        "        M = M.detach()\n",
        "        if self.opt.A:\n",
        "            A = A.detach()\n",
        "        else:\n",
        "            A = 0.\n",
        "        if self.opt.C:\n",
        "            theta = self.theta(x)\n",
        "            phi = self.phi(x)\n",
        "            C = torch.mm(theta, phi.permute(1, 0))\n",
        "            if self.opt.CM:\n",
        "                tmp = torch.exp(C - torch.max(C*M, dim=-1, keepdim=True)[0]) * M\n",
        "                A += tmp / tmp.sum(dim=-1, keepdim=True)\n",
        "            else:\n",
        "                A += F.softmax(C, dim=-1)\n",
        "        if self.opt.residual:\n",
        "            out = self.conv_d(torch.bmm(A, x.permute(0, 2, 1)).permute(0, 2, 1)) + self.down(x)\n",
        "        else:\n",
        "            out = self.conv_d(torch.mm(A, x))\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_A(dim, width=3):\n",
        "        A = torch.zeros(dim, dim, device='cuda', requires_grad=False)\n",
        "        min_value = -(width - 1) // 2\n",
        "        extent = [min_value+i for i in range(width)]\n",
        "        for i in range(dim):\n",
        "            for j in extent:\n",
        "                if i+j >=0 and i+j <=dim-1:\n",
        "                  A[i, i+j] = 1.\n",
        "        M = A\n",
        "        A = A/A.sum(dim=1, keepdim=True)\n",
        "        return A, M\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INPUTDATA**\n",
        " Module to test and train input is the directory containing pickle file"
      ],
      "metadata": {
        "id": "ttoZ3AS8fI34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kjE1pgLsqkd1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle5 as pickle\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "\n",
        "class InputData(object):\n",
        "    def __init__(self, folder_name, shuffle=True):\n",
        "        \"\"\"\n",
        "        Note: Existing non data files in the folder will raise an exception\n",
        "        :param folder_name: The name of folder only including data files\n",
        "        :param shuffle: Whether shuffle data in each files or not\n",
        "        \"\"\"\n",
        "        #print(folder_name)\n",
        "        self.files_list = [''.join([folder_name, '/', i]) for i in os.listdir(folder_name)]\n",
        "        \n",
        "        self.num_file = len(self.files_list)\n",
        "        self.shuffle = shuffle\n",
        "        if shuffle:\n",
        "            self.order_files = random.sample(list(range(self.num_file)), self.num_file)\n",
        "            self.files_list = [self.files_list[i] for i in self.order_files]\n",
        "            \n",
        "        else:\n",
        "            self.order_files = list(range(self.num_file))\n",
        "        self.current_file_index = 0\n",
        "        self.current_video_index = 0\n",
        "        \n",
        "        \n",
        "        with open(self.files_list[0], 'rb') as f:\n",
        "            self.data = pickle.load(f)\n",
        "            # print(self.files_list[self.current_file_index])  ##\n",
        "        self.num_feature = len(self.data)\n",
        "        if shuffle:\n",
        "            self.order_feature = random.sample(list(range(self.num_feature)), self.num_feature)\n",
        "            self.data = [self.data[i] for i in self.order_feature]\n",
        "        else:\n",
        "            self.order_feature = list(range(self.num_feature))\n",
        "\n",
        "    def __check_index(self, size):\n",
        "        if self.current_video_index + size <= self.num_feature:\n",
        "            data = self.data[self.current_video_index: self.current_video_index+size]\n",
        "            self.current_video_index += size\n",
        "            return data\n",
        "        else:\n",
        "            num_excess = self.current_video_index + size - self.num_feature\n",
        "            data1 = self.data[self.current_video_index: self.num_feature]\n",
        "            self.current_file_index += 1\n",
        "            if self.current_file_index == self.num_file:\n",
        "                if self.shuffle:\n",
        "                    self.order_files = random.sample(list(range(self.num_file)), self.num_file)\n",
        "                    self.files_list = [self.files_list[i] for i in self.order_files]\n",
        "                else:\n",
        "                    self.order_files = list(range(self.num_file))\n",
        "                self.current_file_index = 0\n",
        "            with open(self.files_list[self.current_file_index], 'rb') as f:\n",
        "                self.data = pickle.load(f)\n",
        "            self.num_feature = len(self.data)\n",
        "            if self.shuffle:\n",
        "                self.order_feature = random.sample(list(range(self.num_feature)), self.num_feature)\n",
        "                self.data = [self.data[i] for i in self.order_feature]\n",
        "            else:\n",
        "                self.order_feature = list(range(self.num_feature))\n",
        "            data2 = self.data[0: num_excess]\n",
        "            self.current_video_index = num_excess\n",
        "            return data1 + data2\n",
        "    \n",
        "    def next_batch(self, size):\n",
        "        data = self.__check_index(size)\n",
        "        feature = []\n",
        "        labels = []\n",
        "        dims = []\n",
        "        for i in range(size):\n",
        "            # if data[i]['feature'].shape[0] > 400 and data[i]['feature'].ndim != 1:\n",
        "            #     feat = data[i]['feature'][0: 400, :]\n",
        "            #     feature.append(feat)\n",
        "            # else:\n",
        "            feature.append(data[i]['feature'])\n",
        "            \n",
        "            if data[i]['label'] == 0:\n",
        "                labels.append([0.])\n",
        "            else:\n",
        "                labels.append([1.])\n",
        "            dims.append(data[i]['num'])\n",
        "        return feature, np.array(labels, dtype=np.float32), np.array(dims, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN"
      ],
      "metadata": {
        "id": "7bdTIXkLffVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6sPhCzXqrsf",
        "outputId": "a8b69748-06d4-4b26-9f80-7d2eae5cf7c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyper-parameters:\n",
            "batch_size: 10\n",
            "iterations: 5\n",
            "epochs: 100\n",
            "lr: 0.0005\n",
            "restore: False\n",
            "sal_coe: 0.5\n",
            "weight_decay: 2e-06\n",
            "sal_ratio: 0.3\n",
            "save_path: /content/drive/MyDrive/train_out_3/checkpoints/\n",
            "gpu_list: [0]\n",
            "TEST: True\n",
            "A: True\n",
            "C: False\n",
            "CM: True\n",
            "residual: False\n",
            "num_gcn: 1\n",
            "width: 3\n",
            "[*] Current epochs: 0 ---\n",
            "Loss: 0.685, Inverse Loss: 0.575, sal_loss: 0.000\n",
            "[*] Current epochs: 1 ---\n",
            "Loss: 0.701, Inverse Loss: 0.527, sal_loss: 0.000\n",
            "[*] Current epochs: 2 ---\n",
            "Loss: 0.678, Inverse Loss: 0.554, sal_loss: 0.000\n",
            "[*] Current epochs: 3 ---\n",
            "Loss: 0.680, Inverse Loss: 0.527, sal_loss: 0.001\n",
            "[*] Current epochs: 4 ---\n",
            "Loss: 0.692, Inverse Loss: 0.483, sal_loss: 0.001\n",
            "[*] Current epochs: 5 ---\n",
            "Loss: 0.644, Inverse Loss: 0.587, sal_loss: 0.002\n",
            "[*] Current epochs: 6 ---\n",
            "Loss: 0.698, Inverse Loss: 0.439, sal_loss: 0.001\n",
            "[*] Current epochs: 7 ---\n",
            "Loss: 0.662, Inverse Loss: 0.524, sal_loss: 0.001\n",
            "[*] Current epochs: 8 ---\n",
            "Loss: 0.660, Inverse Loss: 0.523, sal_loss: 0.001\n",
            "[*] Current epochs: 9 ---\n",
            "Loss: 0.667, Inverse Loss: 0.485, sal_loss: 0.001\n",
            "[*] Current epochs: 10 ---\n",
            "Loss: 0.651, Inverse Loss: 0.541, sal_loss: 0.002\n",
            "[*] Current epochs: 11 ---\n",
            "Loss: 0.663, Inverse Loss: 0.491, sal_loss: 0.001\n",
            "[*] Current epochs: 12 ---\n",
            "Loss: 0.658, Inverse Loss: 0.512, sal_loss: 0.003\n",
            "[*] Current epochs: 13 ---\n",
            "Loss: 0.652, Inverse Loss: 0.519, sal_loss: 0.003\n",
            "[*] Current epochs: 14 ---\n",
            "Loss: 0.665, Inverse Loss: 0.480, sal_loss: 0.003\n",
            "[*] Current epochs: 15 ---\n",
            "Loss: 0.636, Inverse Loss: 0.560, sal_loss: 0.004\n",
            "[*] Current epochs: 16 ---\n",
            "Loss: 0.662, Inverse Loss: 0.484, sal_loss: 0.004\n",
            "[*] Current epochs: 17 ---\n",
            "Loss: 0.630, Inverse Loss: 0.567, sal_loss: 0.004\n",
            "[*] Current epochs: 18 ---\n",
            "Loss: 0.649, Inverse Loss: 0.514, sal_loss: 0.004\n",
            "[*] Current epochs: 19 ---\n",
            "Loss: 0.653, Inverse Loss: 0.501, sal_loss: 0.005\n",
            "[*] Current epochs: 20 ---\n",
            "Loss: 0.625, Inverse Loss: 0.577, sal_loss: 0.007\n",
            "[*] Current epochs: 21 ---\n",
            "Loss: 0.614, Inverse Loss: 0.608, sal_loss: 0.008\n",
            "[*] Current epochs: 22 ---\n",
            "Loss: 0.650, Inverse Loss: 0.505, sal_loss: 0.010\n",
            "[*] Current epochs: 23 ---\n",
            "Loss: 0.637, Inverse Loss: 0.540, sal_loss: 0.012\n",
            "[*] Current epochs: 24 ---\n",
            "Loss: 0.621, Inverse Loss: 0.577, sal_loss: 0.013\n",
            "[*] Current epochs: 25 ---\n",
            "Loss: 0.615, Inverse Loss: 0.599, sal_loss: 0.017\n",
            "[*] Current epochs: 26 ---\n",
            "Loss: 0.654, Inverse Loss: 0.475, sal_loss: 0.018\n",
            "[*] Current epochs: 27 ---\n",
            "Loss: 0.591, Inverse Loss: 0.644, sal_loss: 0.020\n",
            "[*] Current epochs: 28 ---\n",
            "Loss: 0.630, Inverse Loss: 0.557, sal_loss: 0.027\n",
            "[*] Current epochs: 29 ---\n",
            "Loss: 0.643, Inverse Loss: 0.523, sal_loss: 0.032\n",
            "[*] Current epochs: 30 ---\n",
            "Loss: 0.603, Inverse Loss: 0.608, sal_loss: 0.039\n",
            "[*] Current epochs: 31 ---\n",
            "Loss: 0.613, Inverse Loss: 0.597, sal_loss: 0.041\n",
            "31\n",
            "[*] Current epochs: 32 ---\n",
            "Loss: 0.593, Inverse Loss: 0.636, sal_loss: 0.046\n",
            "32\n",
            "[*] Current epochs: 33 ---\n",
            "Loss: 0.623, Inverse Loss: 0.565, sal_loss: 0.055\n",
            "33\n",
            "[*] Current epochs: 34 ---\n",
            "Loss: 0.582, Inverse Loss: 0.671, sal_loss: 0.060\n",
            "34\n",
            "[*] Current epochs: 35 ---\n",
            "Loss: 0.622, Inverse Loss: 0.570, sal_loss: 0.071\n",
            "35\n",
            "[*] Current epochs: 36 ---\n",
            "Loss: 0.588, Inverse Loss: 0.645, sal_loss: 0.072\n",
            "36\n",
            "[*] Current epochs: 37 ---\n",
            "Loss: 0.591, Inverse Loss: 0.650, sal_loss: 0.080\n",
            "37\n",
            "[*] Current epochs: 38 ---\n",
            "Loss: 0.602, Inverse Loss: 0.632, sal_loss: 0.091\n",
            "38\n",
            "[*] Current epochs: 39 ---\n",
            "Loss: 0.552, Inverse Loss: 0.728, sal_loss: 0.095\n",
            "39\n",
            "[*] Current epochs: 40 ---\n",
            "Loss: 0.618, Inverse Loss: 0.594, sal_loss: 0.102\n",
            "40\n",
            "[*] Current epochs: 41 ---\n",
            "Loss: 0.582, Inverse Loss: 0.670, sal_loss: 0.108\n",
            "41\n",
            "[*] Current epochs: 42 ---\n",
            "Loss: 0.572, Inverse Loss: 0.703, sal_loss: 0.111\n",
            "42\n",
            "[*] Current epochs: 43 ---\n",
            "Loss: 0.595, Inverse Loss: 0.622, sal_loss: 0.110\n",
            "43\n",
            "[*] Current epochs: 44 ---\n",
            "Loss: 0.561, Inverse Loss: 0.699, sal_loss: 0.121\n",
            "44\n",
            "[*] Current epochs: 45 ---\n",
            "Loss: 0.582, Inverse Loss: 0.661, sal_loss: 0.124\n",
            "45\n",
            "[*] Current epochs: 46 ---\n",
            "Loss: 0.587, Inverse Loss: 0.641, sal_loss: 0.118\n",
            "46\n",
            "[*] Current epochs: 47 ---\n",
            "Loss: 0.568, Inverse Loss: 0.684, sal_loss: 0.127\n",
            "47\n",
            "[*] Current epochs: 48 ---\n",
            "Loss: 0.541, Inverse Loss: 0.727, sal_loss: 0.128\n",
            "48\n",
            "[*] Current epochs: 49 ---\n",
            "Loss: 0.569, Inverse Loss: 0.681, sal_loss: 0.128\n",
            "49\n",
            "[*] Current epochs: 50 ---\n",
            "Loss: 0.565, Inverse Loss: 0.656, sal_loss: 0.125\n",
            "50\n",
            "[*] Current epochs: 51 ---\n",
            "Loss: 0.528, Inverse Loss: 0.785, sal_loss: 0.133\n",
            "51\n",
            "[*] Current epochs: 52 ---\n",
            "Loss: 0.569, Inverse Loss: 0.646, sal_loss: 0.131\n",
            "52\n",
            "[*] Current epochs: 53 ---\n",
            "Loss: 0.571, Inverse Loss: 0.650, sal_loss: 0.128\n",
            "53\n",
            "[*] Current epochs: 54 ---\n",
            "Loss: 0.544, Inverse Loss: 0.710, sal_loss: 0.130\n",
            "54\n",
            "[*] Current epochs: 55 ---\n",
            "Loss: 0.572, Inverse Loss: 0.638, sal_loss: 0.126\n",
            "55\n",
            "[*] Current epochs: 56 ---\n",
            "Loss: 0.532, Inverse Loss: 0.727, sal_loss: 0.130\n",
            "56\n",
            "[*] Current epochs: 57 ---\n",
            "Loss: 0.558, Inverse Loss: 0.670, sal_loss: 0.130\n",
            "57\n",
            "[*] Current epochs: 58 ---\n",
            "Loss: 0.521, Inverse Loss: 0.752, sal_loss: 0.132\n",
            "58\n",
            "[*] Current epochs: 59 ---\n",
            "Loss: 0.534, Inverse Loss: 0.712, sal_loss: 0.132\n",
            "59\n",
            "[*] Current epochs: 60 ---\n",
            "Loss: 0.552, Inverse Loss: 0.672, sal_loss: 0.129\n",
            "60\n",
            "[*] Current epochs: 61 ---\n",
            "Loss: 0.559, Inverse Loss: 0.645, sal_loss: 0.128\n",
            "61\n",
            "[*] Current epochs: 62 ---\n",
            "Loss: 0.538, Inverse Loss: 0.700, sal_loss: 0.132\n",
            "62\n",
            "[*] Current epochs: 63 ---\n",
            "Loss: 0.554, Inverse Loss: 0.662, sal_loss: 0.128\n",
            "63\n",
            "[*] Current epochs: 64 ---\n",
            "Loss: 0.490, Inverse Loss: 0.790, sal_loss: 0.131\n",
            "64\n",
            "[*] Current epochs: 65 ---\n",
            "Loss: 0.575, Inverse Loss: 0.604, sal_loss: 0.127\n",
            "65\n",
            "[*] Current epochs: 66 ---\n",
            "Loss: 0.553, Inverse Loss: 0.639, sal_loss: 0.127\n",
            "66\n",
            "[*] Current epochs: 67 ---\n",
            "Loss: 0.515, Inverse Loss: 0.756, sal_loss: 0.136\n",
            "67\n",
            "[*] Current epochs: 68 ---\n",
            "Loss: 0.544, Inverse Loss: 0.664, sal_loss: 0.130\n",
            "68\n",
            "[*] Current epochs: 69 ---\n",
            "Loss: 0.527, Inverse Loss: 0.703, sal_loss: 0.131\n",
            "69\n",
            "[*] Current epochs: 70 ---\n",
            "Loss: 0.535, Inverse Loss: 0.695, sal_loss: 0.132\n",
            "70\n",
            "[*] Current epochs: 71 ---\n",
            "Loss: 0.528, Inverse Loss: 0.683, sal_loss: 0.130\n",
            "71\n",
            "[*] Current epochs: 72 ---\n",
            "Loss: 0.544, Inverse Loss: 0.647, sal_loss: 0.128\n",
            "72\n",
            "[*] Current epochs: 73 ---\n",
            "Loss: 0.506, Inverse Loss: 0.756, sal_loss: 0.136\n",
            "73\n",
            "[*] Current epochs: 74 ---\n",
            "Loss: 0.514, Inverse Loss: 0.728, sal_loss: 0.133\n",
            "74\n",
            "[*] Current epochs: 75 ---\n",
            "Loss: 0.539, Inverse Loss: 0.661, sal_loss: 0.129\n",
            "75\n",
            "[*] Current epochs: 76 ---\n",
            "Loss: 0.542, Inverse Loss: 0.640, sal_loss: 0.129\n",
            "76\n",
            "[*] Current epochs: 77 ---\n",
            "Loss: 0.534, Inverse Loss: 0.676, sal_loss: 0.130\n",
            "77\n",
            "[*] Current epochs: 78 ---\n",
            "Loss: 0.519, Inverse Loss: 0.705, sal_loss: 0.133\n",
            "78\n",
            "[*] Current epochs: 79 ---\n",
            "Loss: 0.525, Inverse Loss: 0.671, sal_loss: 0.131\n",
            "79\n",
            "[*] Current epochs: 80 ---\n",
            "Loss: 0.528, Inverse Loss: 0.677, sal_loss: 0.128\n",
            "80\n",
            "[*] Current epochs: 81 ---\n",
            "Loss: 0.516, Inverse Loss: 0.695, sal_loss: 0.131\n",
            "81\n",
            "[*] Current epochs: 82 ---\n",
            "Loss: 0.521, Inverse Loss: 0.689, sal_loss: 0.132\n",
            "82\n",
            "[*] Current epochs: 83 ---\n",
            "Loss: 0.514, Inverse Loss: 0.704, sal_loss: 0.130\n",
            "83\n",
            "[*] Current epochs: 84 ---\n",
            "Loss: 0.507, Inverse Loss: 0.725, sal_loss: 0.135\n",
            "84\n",
            "[*] Current epochs: 85 ---\n",
            "Loss: 0.547, Inverse Loss: 0.613, sal_loss: 0.126\n",
            "85\n",
            "[*] Current epochs: 86 ---\n",
            "Loss: 0.495, Inverse Loss: 0.744, sal_loss: 0.136\n",
            "86\n",
            "[*] Current epochs: 87 ---\n",
            "Loss: 0.552, Inverse Loss: 0.585, sal_loss: 0.123\n",
            "87\n",
            "[*] Current epochs: 88 ---\n",
            "Loss: 0.498, Inverse Loss: 0.720, sal_loss: 0.132\n",
            "88\n",
            "[*] Current epochs: 89 ---\n",
            "Loss: 0.512, Inverse Loss: 0.706, sal_loss: 0.134\n",
            "89\n",
            "[*] Current epochs: 90 ---\n",
            "Loss: 0.528, Inverse Loss: 0.650, sal_loss: 0.128\n",
            "90\n",
            "[*] Current epochs: 91 ---\n",
            "Loss: 0.529, Inverse Loss: 0.638, sal_loss: 0.127\n",
            "91\n",
            "[*] Current epochs: 92 ---\n",
            "Loss: 0.467, Inverse Loss: 0.825, sal_loss: 0.144\n",
            "92\n",
            "[*] Current epochs: 93 ---\n",
            "Loss: 0.558, Inverse Loss: 0.551, sal_loss: 0.122\n",
            "93\n",
            "[*] Current epochs: 94 ---\n",
            "Loss: 0.514, Inverse Loss: 0.688, sal_loss: 0.131\n",
            "94\n",
            "[*] Current epochs: 95 ---\n",
            "Loss: 0.493, Inverse Loss: 0.724, sal_loss: 0.133\n",
            "95\n",
            "[*] Current epochs: 96 ---\n",
            "Loss: 0.530, Inverse Loss: 0.619, sal_loss: 0.124\n",
            "96\n",
            "[*] Current epochs: 97 ---\n",
            "Loss: 0.507, Inverse Loss: 0.698, sal_loss: 0.134\n",
            "97\n",
            "[*] Current epochs: 98 ---\n",
            "Loss: 0.529, Inverse Loss: 0.631, sal_loss: 0.129\n",
            "98\n",
            "[*] Current epochs: 99 ---\n",
            "Loss: 0.501, Inverse Loss: 0.704, sal_loss: 0.131\n",
            "99\n",
            "<All keys matched successfully>\n",
            "Epoch: 31, AUC: 0.8321978319783196\n",
            "<All keys matched successfully>\n",
            "Epoch: 32, AUC: 0.8312018970189702\n",
            "<All keys matched successfully>\n",
            "Epoch: 33, AUC: 0.8298387533875339\n",
            "<All keys matched successfully>\n",
            "Epoch: 34, AUC: 0.827509485094851\n",
            "<All keys matched successfully>\n",
            "Epoch: 35, AUC: 0.8270230352303523\n",
            "<All keys matched successfully>\n",
            "Epoch: 36, AUC: 0.8274674796747968\n",
            "<All keys matched successfully>\n",
            "Epoch: 37, AUC: 0.8266084010840108\n",
            "<All keys matched successfully>\n",
            "Epoch: 38, AUC: 0.8260108401084011\n",
            "<All keys matched successfully>\n",
            "Epoch: 39, AUC: 0.8248658536585366\n",
            "<All keys matched successfully>\n",
            "Epoch: 40, AUC: 0.8243523035230352\n",
            "<All keys matched successfully>\n",
            "Epoch: 41, AUC: 0.825369918699187\n",
            "<All keys matched successfully>\n",
            "Epoch: 42, AUC: 0.8246571815718157\n",
            "<All keys matched successfully>\n",
            "Epoch: 43, AUC: 0.8249796747967482\n",
            "<All keys matched successfully>\n",
            "Epoch: 44, AUC: 0.824559620596206\n",
            "<All keys matched successfully>\n",
            "Epoch: 45, AUC: 0.8246571815718158\n",
            "<All keys matched successfully>\n",
            "Epoch: 46, AUC: 0.8248699186991869\n",
            "<All keys matched successfully>\n",
            "Epoch: 47, AUC: 0.8247574525745259\n",
            "<All keys matched successfully>\n",
            "Epoch: 48, AUC: 0.8241951219512195\n",
            "<All keys matched successfully>\n",
            "Epoch: 49, AUC: 0.8236639566395663\n",
            "<All keys matched successfully>\n",
            "Epoch: 50, AUC: 0.8226219512195122\n",
            "<All keys matched successfully>\n",
            "Epoch: 51, AUC: 0.82170054200542\n",
            "<All keys matched successfully>\n",
            "Epoch: 52, AUC: 0.8210623306233064\n",
            "<All keys matched successfully>\n",
            "Epoch: 53, AUC: 0.8207845528455285\n",
            "<All keys matched successfully>\n",
            "Epoch: 54, AUC: 0.8207506775067751\n",
            "<All keys matched successfully>\n",
            "Epoch: 55, AUC: 0.8209173441734418\n",
            "<All keys matched successfully>\n",
            "Epoch: 56, AUC: 0.8204878048780487\n",
            "<All keys matched successfully>\n",
            "Epoch: 57, AUC: 0.8200840108401085\n",
            "<All keys matched successfully>\n",
            "Epoch: 58, AUC: 0.8196761517615178\n",
            "<All keys matched successfully>\n",
            "Epoch: 59, AUC: 0.8186585365853659\n",
            "<All keys matched successfully>\n",
            "Epoch: 60, AUC: 0.8178509485094851\n",
            "<All keys matched successfully>\n",
            "Epoch: 61, AUC: 0.8175826558265583\n",
            "<All keys matched successfully>\n",
            "Epoch: 62, AUC: 0.817920054200542\n",
            "<All keys matched successfully>\n",
            "Epoch: 63, AUC: 0.8178644986449864\n",
            "<All keys matched successfully>\n",
            "Epoch: 64, AUC: 0.8175542005420054\n",
            "<All keys matched successfully>\n",
            "Epoch: 65, AUC: 0.8168387533875339\n",
            "<All keys matched successfully>\n",
            "Epoch: 66, AUC: 0.8166138211382115\n",
            "<All keys matched successfully>\n",
            "Epoch: 67, AUC: 0.816220867208672\n",
            "<All keys matched successfully>\n",
            "Epoch: 68, AUC: 0.815909214092141\n",
            "<All keys matched successfully>\n",
            "Epoch: 69, AUC: 0.8156910569105691\n",
            "<All keys matched successfully>\n",
            "Epoch: 70, AUC: 0.8151490514905149\n",
            "<All keys matched successfully>\n",
            "Epoch: 71, AUC: 0.8147452574525745\n",
            "<All keys matched successfully>\n",
            "Epoch: 72, AUC: 0.8145027100271003\n",
            "<All keys matched successfully>\n",
            "Epoch: 73, AUC: 0.8143346883468834\n",
            "<All keys matched successfully>\n",
            "Epoch: 74, AUC: 0.8138956639566396\n",
            "<All keys matched successfully>\n",
            "Epoch: 75, AUC: 0.8133333333333334\n",
            "<All keys matched successfully>\n",
            "Epoch: 76, AUC: 0.8132032520325204\n",
            "<All keys matched successfully>\n",
            "Epoch: 77, AUC: 0.8131287262872628\n",
            "<All keys matched successfully>\n",
            "Epoch: 78, AUC: 0.8127289972899729\n",
            "<All keys matched successfully>\n",
            "Epoch: 79, AUC: 0.8127032520325205\n",
            "<All keys matched successfully>\n",
            "Epoch: 80, AUC: 0.8124417344173441\n",
            "<All keys matched successfully>\n",
            "Epoch: 81, AUC: 0.8120785907859077\n",
            "<All keys matched successfully>\n",
            "Epoch: 82, AUC: 0.812081300813008\n",
            "<All keys matched successfully>\n",
            "Epoch: 83, AUC: 0.8117398373983741\n",
            "<All keys matched successfully>\n",
            "Epoch: 84, AUC: 0.81150135501355\n",
            "<All keys matched successfully>\n",
            "Epoch: 85, AUC: 0.8111924119241192\n",
            "<All keys matched successfully>\n",
            "Epoch: 86, AUC: 0.8108238482384825\n",
            "<All keys matched successfully>\n",
            "Epoch: 87, AUC: 0.8106991869918698\n",
            "<All keys matched successfully>\n",
            "Epoch: 88, AUC: 0.8104756097560974\n",
            "<All keys matched successfully>\n",
            "Epoch: 89, AUC: 0.8102669376693767\n",
            "<All keys matched successfully>\n",
            "Epoch: 90, AUC: 0.8101368563685637\n",
            "<All keys matched successfully>\n",
            "Epoch: 91, AUC: 0.8101517615176151\n",
            "<All keys matched successfully>\n",
            "Epoch: 92, AUC: 0.8099268292682926\n",
            "<All keys matched successfully>\n",
            "Epoch: 93, AUC: 0.8096747967479674\n",
            "<All keys matched successfully>\n",
            "Epoch: 94, AUC: 0.8093319783197831\n",
            "<All keys matched successfully>\n",
            "Epoch: 95, AUC: 0.8092737127371274\n",
            "<All keys matched successfully>\n",
            "Epoch: 96, AUC: 0.8089376693766938\n",
            "<All keys matched successfully>\n",
            "Epoch: 97, AUC: 0.8086436314363143\n",
            "<All keys matched successfully>\n",
            "Epoch: 98, AUC: 0.8084579945799458\n",
            "<All keys matched successfully>\n",
            "Epoch: 99, AUC: 0.8081070460704606\n",
            "Best_Epoch: 31, Best_AUC: 0.8321978319783196\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import csv\n",
        "import argparse\n",
        "\n",
        "import pdb\n",
        "\n",
        "train_feature_code_path = '/content/drive/MyDrive/data/train'\n",
        "test_feature_code_path = '/content/drive/MyDrive/data/test'\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    # input for training\n",
        "    parser.add_argument('--batch_size', default=10, type=int)\n",
        "    parser.add_argument('--iterations', default=5, type=int)\n",
        "    parser.add_argument('--epochs', default=100, type=int)\n",
        "    parser.add_argument('--lr', default=0.5e-3, type=float)\n",
        "    parser.add_argument('--restore', default=False, type=bool)\n",
        "    parser.add_argument('--sal_coe', default=0.5, type=float)\n",
        "    parser.add_argument('--weight_decay', default=0.2e-5, type=float)\n",
        "    parser.add_argument('--sal_ratio', default=0.3, type=float)\n",
        "    parser.add_argument('--save_path', default='/content/drive/MyDrive/train_out_3/checkpoints/', type=str)\n",
        "    parser.add_argument('--gpu_list', default=[0], type=list)\n",
        "    parser.add_argument('--TEST', default=True, type=bool)\n",
        "    parser.add_argument('--A', action='store_false')\n",
        "    parser.add_argument('--C', action='store_true')\n",
        "    parser.add_argument('--CM', action='store_false')\n",
        "    parser.add_argument('--residual', action='store_true')\n",
        "    parser.add_argument('--num_gcn', default=1, type=int)\n",
        "    parser.add_argument('--width', default=3, type=int)\n",
        "    args,unknown = parser.parse_known_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "def tower_loss(net, features, labels, dims, args):\n",
        "    loss = []\n",
        "    inverse_loss = []\n",
        "    sum_sal_loss = []\n",
        "    labels = torch.from_numpy(labels).cuda()\n",
        "    for i in range(len(features)):\n",
        "        feature = torch.from_numpy(features[i]).cuda()\n",
        "        feature=feature.type(torch.cuda.FloatTensor) \n",
        "        video_score, inverse_video_score, mask, seg_scores = net(feature)\n",
        "        entropy_loss = F.binary_cross_entropy_with_logits(video_score, labels[i: i+1, :])\n",
        "        margin = torch.max(torch.tensor(0., device='cuda', requires_grad=False), (torch.sigmoid(seg_scores) - mask) ** 2 - args.sal_ratio ** 2)\n",
        "        count_nonzero = (margin != 0.).sum().detach().to(torch.float32)\n",
        "        sal_loss = torch.sum(margin) / (count_nonzero + 1e-6)\n",
        "        inverse_entropy_loss = labels[i, 0] * F.binary_cross_entropy_with_logits(inverse_video_score, torch.tensor([[0.]], requires_grad=False, device='cuda'))\n",
        "        loss.append(entropy_loss)\n",
        "        inverse_loss.append(inverse_entropy_loss + args.sal_coe * sal_loss)\n",
        "        m=sum(inverse_loss) / args.batch_size\n",
        "        sum_sal_loss.append(args.sal_coe * sal_loss)\n",
        "    return sum(loss) / args.batch_size,m , sum(sum_sal_loss) / args.batch_size\n",
        "\n",
        "\n",
        "def train():\n",
        "    args = parse_args()\n",
        "    print('Hyper-parameters:')\n",
        "    d_args = vars(args)\n",
        "    for i in d_args:\n",
        "        print('{}: {}'.format(i, d_args[i]))\n",
        "    gpu_list = args.gpu_list\n",
        "    num_gpus = len(gpu_list)\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([str(i) for i in gpu_list])\n",
        "    net = Network(args)\n",
        "    net.to('cuda')\n",
        "    net.train()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "    optimizer_ass = torch.optim.Adam(net.attention.parameters(), lr=args.lr)\n",
        "    train_data = InputData(train_feature_code_path, shuffle=True)\n",
        "    if not os.path.exists(args.save_path):\n",
        "        os.makedirs(args.save_path)\n",
        "    for i in range(args.epochs):\n",
        "        print('[*] Current epochs: %d ---' % i)\n",
        "        sum_loss = 0.\n",
        "        sum_inverse_loss = 0.0\n",
        "        sum_sum_sal_loss = 0.0\n",
        "        for j in range(args.iterations):\n",
        "            list_features, numpy_labels, numpy_dims = train_data.next_batch(size=args.batch_size)\n",
        "            loss, inverse_loss, sum_sal_loss = tower_loss(net, list_features, numpy_labels, numpy_dims, args)\n",
        "            optimizer.zero_grad()\n",
        "            optimizer_ass.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "            optimizer.step()\n",
        "            torch.autograd.set_detect_anomaly(True)\n",
        "            inverse_loss.backward()\n",
        "            optimizer_ass.step()\n",
        "            sum_loss += loss.item()\n",
        "            sum_inverse_loss += inverse_loss.item()\n",
        "            sum_sum_sal_loss += sum_sal_loss.item()\n",
        "        print('Loss: {:.3f}, Inverse Loss: {:.3f}, sal_loss: {:.3f}'.format(sum_loss / args.iterations, sum_inverse_loss / args.iterations, sum_sum_sal_loss / args.iterations))\n",
        "        if i > 30:\n",
        "            print(i)\n",
        "            torch.save(net.state_dict(), args.save_path + '{}.param'.format(i))\n",
        "    if args.TEST:\n",
        "        test(args)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Needed for test"
      ],
      "metadata": {
        "id": "-KIKsnIxfoeR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq46eG7_trwU",
        "outputId": "2b011728-3fe8-4605-eb8c-5702002d283c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 26.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "lU1UBFwTfs2J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8VS49lS_uCiC"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "import numpy as np\n",
        "import pickle5 as pickle\n",
        "import torch\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import xlsxwriter\n",
        "import pdb\n",
        "from scipy.interpolate import interp1d\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    # input for training\n",
        "    parser.add_argument('--batch_size', default=10, type=int)\n",
        "    parser.add_argument('--iterations', default=3, type=int)\n",
        "    parser.add_argument('--epochs', default=80, type=int)\n",
        "    parser.add_argument('--lr', default=0.5e-3, type=float)\n",
        "    parser.add_argument('--restore', default=False, type=bool)\n",
        "    parser.add_argument('--sal_coe', default=0.5, type=float)\n",
        "    parser.add_argument('--weight_decay', default=0.2e-5, type=float)\n",
        "    parser.add_argument('--sal_ratio', default=0.3, type=float)\n",
        "    parser.add_argument('--save_path', default='/content/drive/MyDrive/train_out_3/checkpoints/', type=str)\n",
        "    parser.add_argument('--gpu_list', default=[0], type=list)\n",
        "    parser.add_argument('--TEST', default=True, type=bool)\n",
        "\n",
        "    parser.add_argument('--A', action='store_false')\n",
        "    parser.add_argument('--B', action='store_false')\n",
        "    parser.add_argument('--C', action='store_true')\n",
        "    parser.add_argument('--BM', action='store_false')\n",
        "    parser.add_argument('--CM', action='store_false')\n",
        "    parser.add_argument('--residual', action='store_true')\n",
        "    parser.add_argument('--num_gcn', default=1, type=int)\n",
        "    parser.add_argument('--width', default=3, type=int)\n",
        "    args,unknown = parser.parse_known_args()\n",
        "    return args\n",
        "\n",
        "def test(args):\n",
        "    def draw_roc(tpr, fpr, auc):\n",
        "        plt.figure()\n",
        "        lw = 2\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.4f)' % auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.0])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic example')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.savefig(\"./test.png\")\n",
        "        plt.cla()\n",
        "        plt.clf()\n",
        "        plt.close()\n",
        "\n",
        "    gts = np.load('/content/drive/MyDrive/mini/Contrastive-Attention-for-Video-Anomaly-Detection-main/gts.npy',allow_pickle=True)\n",
        "\n",
        "    test_features = test_data = InputData('/content/drive/MyDrive/data/test', shuffle=False)\n",
        "    net = Network(args).to('cuda')\n",
        "    net.eval()\n",
        "    best_auc = 0\n",
        "    best_epoch = 0\n",
        "    with torch.no_grad():\n",
        "        for i in range(31,args.epochs):\n",
        "            workbook = xlsxwriter.Workbook('./record.xlsx')\n",
        "            mask_sheet = workbook.add_worksheet('mask')\n",
        "            score_sheet = workbook.add_worksheet('score')\n",
        "            cell_format = workbook.add_format({'font_color': 'red'})\n",
        "            cell_format2 = workbook.add_format({'font_color': 'blue'})\n",
        "            print(net.load_state_dict(torch.load('/content/drive/MyDrive/train_out_3/checkpoints/' + '{}.param'.format(i))))\n",
        "            \n",
        "            pred = []\n",
        "            y = []\n",
        "            for j in range(2): \n",
        "                features = torch.from_numpy(test_features.next_batch(1)[0][0]).float().cuda()\n",
        "                video_scores, inverse_video_scores, masks, segments_scores = net(Variable(features))\n",
        "                row = np.squeeze(masks.cpu().numpy(), axis=1)\n",
        "                mask_sheet.write_row(j, 1, row.tolist())\n",
        "                mask_sheet.write(j, 0, np.mean(row), cell_format2)\n",
        "                mask_sheet.conditional_format(j, np.argmax(row)+1, j, np.argmax(row)+1, {'type': 'no_errors', 'format': cell_format})\n",
        "                row = np.squeeze(segments_scores.cpu().numpy(), axis=1)\n",
        "                score_sheet.write_row(j, 0, row.tolist())\n",
        "                score_sheet.conditional_format(j, np.argmax(row), j, np.argmax(row), {'type': 'no_errors', 'format': cell_format})\n",
        "                scores = np.squeeze(segments_scores.cpu().numpy())\n",
        "                video_score = video_scores.cpu().numpy()\n",
        "                if video_score[0, 0] < -2:\n",
        "                    scores += video_score[0, 0]\n",
        "                x = np.arange(0, scores.shape[0])\n",
        "                f = interp1d(x, scores, kind='linear', axis=0, fill_value='extrapolate')\n",
        "                scale_x = np.arange(0, scores.shape[0], 1 / 60)\n",
        "                pred += list(f(scale_x))\n",
        "                y += b2[j].tolist()\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
        "            thresholds=list(map(lambda x:x-0.002,thresholds))\n",
        "            auc = metrics.auc(fpr, tpr)\n",
        "            draw_roc(tpr, fpr, auc)\n",
        "            print('Epoch: {}, AUC: {}'.format(i, auc))\n",
        "            if auc > best_auc:\n",
        "                best_auc = auc\n",
        "                best_epoch = i\n",
        "            workbook.close()\n",
        "    print('Best_Epoch: {}, Best_AUC: {}'.format(best_epoch, best_auc))\n",
        "    return best_auc\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "print('Hyper-parameters:')\n",
        "d_args = vars(args)\n",
        "for i in d_args:\n",
        "  print('{}: {}'.format(i, d_args[i]))\n",
        "test(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually creating groundtruth values"
      ],
      "metadata": {
        "id": "Agk60kqsiNf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VGd_V8LMvJaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd7926c-3915-4e99-f923-8705a2ab85cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([0, 0, 0, ..., 0, 0, 0]), array([0, 0, 0, ..., 1, 1, 1])]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a=[0 for i in range(22)]\n",
        "a[2]=1\n",
        "a[3]=1\n",
        "a1=[0 for i in range(24)]\n",
        "a1[21]=a1[22]=a1[23]=1\n",
        "ra1=[]\n",
        "ra2=[]\n",
        "for i in range(len(a)):\n",
        "  for j in range(60):\n",
        "    ra1.append(a[i])\n",
        "for i in range(len(a1)):\n",
        "  for j in range(60):\n",
        "    ra2.append(a1[i])\n",
        "b=np.array(ra1)\n",
        "b1=np.array(ra2)\n",
        "b2=[]\n",
        "b2.append(b)\n",
        "b2.append(b1)\n",
        "print(b2)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}